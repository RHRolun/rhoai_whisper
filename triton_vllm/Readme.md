### Triton vLLM Whisper

We have the model stored in S3 for our inference service to pull down.
